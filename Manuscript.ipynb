{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_idml import idml\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idml = idml.IDMLPackage(\"./Manuscript/two.idml\")\n",
    "idml.extractall(\"./documents/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{http://ns.adobe.com/AdobeInDesign/idml/1.0/packaging}Spread\n",
      "Spread\n",
      "FlattenerPreference\n",
      "Properties\n",
      "RasterVectorBalance\n",
      "Page\n",
      "Properties\n",
      "PageColor\n",
      "Descriptor\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "MarginPreference\n",
      "GridDataInformation\n",
      "Properties\n",
      "AppliedFont\n",
      "TextFrame\n",
      "Properties\n",
      "PathGeometry\n",
      "GeometryPathType\n",
      "PathPointArray\n",
      "PathPointType\n",
      "PathPointType\n",
      "PathPointType\n",
      "PathPointType\n",
      "ObjectExportOption\n",
      "Properties\n",
      "AltMetadataProperty\n",
      "ActualMetadataProperty\n",
      "TextFramePreference\n",
      "Properties\n",
      "InsetSpacing\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "TextWrapPreference\n",
      "Properties\n",
      "TextWrapOffset\n",
      "TextFrame\n",
      "Properties\n",
      "PathGeometry\n",
      "GeometryPathType\n",
      "PathPointArray\n",
      "PathPointType\n",
      "PathPointType\n",
      "PathPointType\n",
      "PathPointType\n",
      "ObjectExportOption\n",
      "Properties\n",
      "AltMetadataProperty\n",
      "ActualMetadataProperty\n",
      "TextFramePreference\n",
      "Properties\n",
      "InsetSpacing\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "ListItem\n",
      "TextWrapPreference\n",
      "Properties\n",
      "TextWrapOffset\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    GET PAGES BY SPREADS\n",
    "'''\n",
    "for spread in idml.spreads:\n",
    "    tree = ET.parse(\"./Manuscript/documents/\" + spread)\n",
    "    root = tree.getroot()\n",
    "    for item in root.iter():\n",
    "        print(item.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<simple_idml.components.Page object at 0x107134a90>\n",
      "<simple_idml.components.Page object at 0x106929ba8>\n",
      "<simple_idml.components.Page object at 0x106d20d30>\n",
      "<simple_idml.components.Page object at 0x106929ba8>\n",
      "<simple_idml.components.Page object at 0x106d20d30>\n",
      "<simple_idml.components.Page object at 0x107346240>\n",
      "<simple_idml.components.Page object at 0x107134748>\n",
      "<simple_idml.components.Page object at 0x107346240>\n",
      "<simple_idml.components.Page object at 0x107134748>\n",
      "<simple_idml.components.Page object at 0x107134d68>\n",
      "<simple_idml.components.Page object at 0x107134710>\n",
      "<simple_idml.components.Page object at 0x107134d68>\n",
      "<simple_idml.components.Page object at 0x107134710>\n",
      "<simple_idml.components.Page object at 0x107134470>\n",
      "<simple_idml.components.Page object at 0x107134780>\n",
      "<simple_idml.components.Page object at 0x107134470>\n",
      "<simple_idml.components.Page object at 0x107134780>\n",
      "<simple_idml.components.Page object at 0x107134518>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    GET PAGE SIZE (width - 498, height - 708) IN POINTS\n",
    "    -------------------------------------------------------\n",
    "    Measurement units in IDML exported from In\n",
    "    Design are always points (defined as 72 units per \n",
    "    inch).\n",
    "'''\n",
    "for page in idml.pages:\n",
    "    for items in page.spread.pages:\n",
    "        print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<simple_idml.components.Page object at 0x107134a90>]\n",
      "[<simple_idml.components.Page object at 0x106929ba8>, <simple_idml.components.Page object at 0x106d20d30>]\n",
      "[<simple_idml.components.Page object at 0x106929ba8>, <simple_idml.components.Page object at 0x106d20d30>]\n",
      "[<simple_idml.components.Page object at 0x107346240>, <simple_idml.components.Page object at 0x107134748>]\n",
      "[<simple_idml.components.Page object at 0x107346240>, <simple_idml.components.Page object at 0x107134748>]\n",
      "[<simple_idml.components.Page object at 0x107134d68>, <simple_idml.components.Page object at 0x107134710>]\n",
      "[<simple_idml.components.Page object at 0x107134d68>, <simple_idml.components.Page object at 0x107134710>]\n",
      "[<simple_idml.components.Page object at 0x107134470>, <simple_idml.components.Page object at 0x107134780>]\n",
      "[<simple_idml.components.Page object at 0x107134470>, <simple_idml.components.Page object at 0x107134780>]\n",
      "[<simple_idml.components.Page object at 0x107134518>]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    GET PAGES WITHIN THE SPREAD\n",
    "'''\n",
    "for spread in idml.pages:\n",
    "    print(spread.spread.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Extract the xml files from provided indesign file\n",
    "'''\n",
    "idml.extractall(\"./documents/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graphic object Resources/Graphic.xml at 0x10702f3c8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idml.graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='utf8'?>\n",
      "<ns0:Spread xmlns:ns0=\"http://ns.adobe.com/AdobeInDesign/idml/1.0/packaging\" DOMVersion=\"14.0\">\n",
      "\t<Spread AllowPageShuffle=\"true\" BindingLocation=\"0\" FlattenerOverride=\"Default\" ItemTransform=\"1 0 0 1 0 0\" PageCount=\"1\" PageTransitionDirection=\"NotApplicable\" PageTransitionDuration=\"Medium\" PageTransitionType=\"None\" Self=\"uc8\" ShowMasterItems=\"true\">\n",
      "\t\t<FlattenerPreference ClipComplexRegions=\"false\" ConvertAllStrokesToOutlines=\"false\" ConvertAllTextToOutlines=\"false\" GradientAndMeshResolution=\"150\" LineArtAndTextResolution=\"300\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<RasterVectorBalance type=\"double\">50</RasterVectorBalance>\n",
      "\t\t\t</Properties>\n",
      "\t\t</FlattenerPreference>\n",
      "\t\t<Page AppliedAlternateLayout=\"uf0\" AppliedMaster=\"uf1\" AppliedTrapPreset=\"TrapPreset/$ID/kDefaultTrapStyleName\" GeometricBounds=\"0 0 708.6614173237 498.8976377953\" GridStartingPoint=\"TopOutside\" ItemTransform=\"1 0 0 1 0 -354.33070866185\" LayoutRule=\"UseMaster\" MasterPageTransform=\"1 0 0 1 0 0\" Name=\"1\" OptionalPage=\"false\" OverrideList=\"\" Self=\"ucd\" SnapshotBlendingMode=\"IgnoreLayoutSnapshots\" TabOrder=\"\" UseMasterGrid=\"true\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<PageColor type=\"enumeration\">UseMasterColor</PageColor>\n",
      "\t\t\t\t<Descriptor type=\"list\">\n",
      "\t\t\t\t\t<ListItem type=\"string\" />\n",
      "\t\t\t\t\t<ListItem type=\"enumeration\">Arabic</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"boolean\">true</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"boolean\">false</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"long\">1</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"string\" />\n",
      "\t\t\t\t</Descriptor>\n",
      "\t\t\t</Properties>\n",
      "\t\t\t<MarginPreference Bottom=\"36\" ColumnCount=\"1\" ColumnDirection=\"Horizontal\" ColumnGutter=\"12\" ColumnsPositions=\"0 426.8976377953\" Left=\"36\" Right=\"36\" Top=\"36\" />\n",
      "\t\t\t<GridDataInformation CharacterAki=\"0\" CharacterAlignment=\"AlignEmCenter\" FontStyle=\"Regular\" GridAlignment=\"AlignEmCenter\" HorizontalScale=\"100\" LineAki=\"9\" LineAlignment=\"LeftOrTopLineJustify\" PointSize=\"12\" VerticalScale=\"100\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<AppliedFont type=\"string\">Minion Pro</AppliedFont>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</GridDataInformation>\n",
      "\t\t</Page>\n",
      "\t\t<TextFrame AppliedObjectStyle=\"ObjectStyle/$ID/[Normal Graphics Frame]\" ContentType=\"TextType\" GradientFillAngle=\"0\" GradientFillHiliteAngle=\"0\" GradientFillHiliteLength=\"0\" GradientFillLength=\"0\" GradientFillStart=\"0 0\" GradientStrokeAngle=\"0\" GradientStrokeHiliteAngle=\"0\" GradientStrokeHiliteLength=\"0\" GradientStrokeLength=\"0\" GradientStrokeStart=\"0 0\" HorizontalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" ItemLayer=\"uc5\" ItemTransform=\"1 0 0 1 249.44881889765 0\" LastUpdatedInterfaceChangeCount=\"\" LocalDisplaySetting=\"Default\" Locked=\"false\" Name=\"$ID/\" NextTextFrame=\"u309\" OverriddenPageItemProps=\"\" ParentInterfaceChangeCount=\"\" ParentStory=\"u2ee\" PreviousTextFrame=\"n\" Self=\"u300\" TargetInterfaceChangeCount=\"\" VerticalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" Visible=\"true\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<PathGeometry>\n",
      "\t\t\t\t\t<GeometryPathType PathOpen=\"false\">\n",
      "\t\t\t\t\t\t<PathPointArray>\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"-212.94881889765 -317.83070866185\" LeftDirection=\"-212.94881889765 -317.83070866185\" RightDirection=\"-212.94881889765 -317.83070866185\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"-212.7292886189514 317.83070866185\" LeftDirection=\"-212.7292886189514 317.83070866185\" RightDirection=\"-212.7292886189514 317.83070866185\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"213.1683491763486 317.83070866185\" LeftDirection=\"213.1683491763486 317.83070866185\" RightDirection=\"213.1683491763486 317.83070866185\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"212.94881889765 -317.83070866185\" LeftDirection=\"212.94881889765 -317.83070866185\" RightDirection=\"212.94881889765 -317.83070866185\" />\n",
      "\t\t\t\t\t\t</PathPointArray>\n",
      "\t\t\t\t\t</GeometryPathType>\n",
      "\t\t\t\t</PathGeometry>\n",
      "\t\t\t</Properties>\n",
      "\t\t\t<ObjectExportOption ActualTextSourceType=\"SourceXMLStructure\" AltTextSourceType=\"SourceXMLStructure\" ApplyTagType=\"TagFromStructure\" CustomActualText=\"$ID/\" CustomAltText=\"$ID/\" CustomImageAlignment=\"false\" CustomLayout=\"false\" CustomLayoutType=\"AlignmentAndSpacing\" CustomSize=\"$ID/\" EpubType=\"$ID/\" GIFOptionsInterlaced=\"true\" GIFOptionsPalette=\"AdaptivePalette\" ImageAlignment=\"AlignLeft\" ImageConversionType=\"JPEG\" ImageExportResolution=\"Ppi300\" ImagePageBreak=\"PageBreakBefore\" ImageSpaceAfter=\"0\" ImageSpaceBefore=\"0\" JPEGOptionsFormat=\"BaselineEncoding\" JPEGOptionsQuality=\"High\" PreserveAppearanceFromLayout=\"PreserveAppearanceDefault\" SizeType=\"DefaultSize\" SpaceUnit=\"CssPixel\" UseImagePageBreak=\"false\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<AltMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
      "\t\t\t\t\t<ActualMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</ObjectExportOption>\n",
      "\t\t\t<TextFramePreference AutoSizingReferencePoint=\"CenterPoint\" AutoSizingType=\"Off\" FirstBaselineOffset=\"AscentOffset\" FootnotesEnableOverrides=\"false\" FootnotesMinimumSpacing=\"12\" FootnotesSpaceBetween=\"6\" FootnotesSpanAcrossColumns=\"false\" IgnoreWrap=\"false\" MinimumFirstBaselineOffset=\"0\" MinimumHeightForAutoSizing=\"0\" MinimumWidthForAutoSizing=\"0\" TextColumnCount=\"1\" TextColumnFixedWidth=\"425.11716807399864\" TextColumnGutter=\"12\" TextColumnMaxWidth=\"0\" UseFixedColumnWidth=\"false\" UseFlexibleColumnWidth=\"false\" UseMinimumHeightForAutoSizing=\"false\" UseMinimumWidthForAutoSizing=\"false\" UseNoLineBreaksForAutoSizing=\"false\" VerticalBalanceColumns=\"false\" VerticalJustification=\"TopAlign\" VerticalThreshold=\"0\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<InsetSpacing type=\"unit\">0</InsetSpacing>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</TextFramePreference>\n",
      "\t\t\t<BaselineFrameGridOption BaselineFrameGridIncrement=\"12\" BaselineFrameGridRelativeOption=\"TopOfInset\" StartingOffsetForBaselineFrameGrid=\"0\" UseCustomBaselineFrameGrid=\"false\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<BaselineFrameGridColor type=\"enumeration\">LightBlue</BaselineFrameGridColor>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</BaselineFrameGridOption>\n",
      "\t\t\t<TextFrameFootnoteOptionsObject EnableOverrides=\"false\" MinimumSpacingOption=\"12\" SpaceBetweenFootnotes=\"6\" SpanFootnotesAcross=\"false\" />\n",
      "\t\t\t<TextWrapPreference ApplyToMasterPageOnly=\"false\" Inverse=\"false\" TextWrapMode=\"None\" TextWrapSide=\"BothSides\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<TextWrapOffset Bottom=\"0\" Left=\"0\" Right=\"0\" Top=\"0\" />\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</TextWrapPreference>\n",
      "\t\t</TextFrame>\n",
      "\t</Spread>\n",
      "</ns0:Spread>\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse('../idml2html/' + idml.spreads[0])\n",
    "print(ET.tostring(tree.getroot(), encoding='utf8').decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='utf8'?>\n",
      "<ns0:Spread xmlns:ns0=\"http://ns.adobe.com/AdobeInDesign/idml/1.0/packaging\" DOMVersion=\"14.0\">\n",
      "\t<Spread AllowPageShuffle=\"true\" BindingLocation=\"1\" FlattenerOverride=\"Default\" ItemTransform=\"1 0 0 1 0 888.6614173237\" PageCount=\"2\" PageTransitionDirection=\"NotApplicable\" PageTransitionDuration=\"Medium\" PageTransitionType=\"None\" Self=\"uce\" ShowMasterItems=\"true\">\n",
      "\t\t<FlattenerPreference ClipComplexRegions=\"false\" ConvertAllStrokesToOutlines=\"false\" ConvertAllTextToOutlines=\"false\" GradientAndMeshResolution=\"150\" LineArtAndTextResolution=\"300\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<RasterVectorBalance type=\"double\">50</RasterVectorBalance>\n",
      "\t\t\t</Properties>\n",
      "\t\t</FlattenerPreference>\n",
      "\t\t<Page AppliedAlternateLayout=\"uf0\" AppliedMaster=\"uf1\" AppliedTrapPreset=\"TrapPreset/$ID/kDefaultTrapStyleName\" GeometricBounds=\"0 0 708.6614173237 498.8976377953\" GridStartingPoint=\"TopOutside\" ItemTransform=\"1 0 0 1 -498.8976377953 -354.33070866185\" LayoutRule=\"UseMaster\" MasterPageTransform=\"1 0 0 1 0 0\" Name=\"2\" OptionalPage=\"false\" OverrideList=\"u1c3 n\" Self=\"ue2\" SnapshotBlendingMode=\"IgnoreLayoutSnapshots\" TabOrder=\"\" UseMasterGrid=\"true\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<PageColor type=\"enumeration\">UseMasterColor</PageColor>\n",
      "\t\t\t\t<Descriptor type=\"list\">\n",
      "\t\t\t\t\t<ListItem type=\"string\" />\n",
      "\t\t\t\t\t<ListItem type=\"enumeration\">Arabic</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"boolean\">true</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"boolean\">false</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"long\">2</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"string\" />\n",
      "\t\t\t\t</Descriptor>\n",
      "\t\t\t</Properties>\n",
      "\t\t\t<MarginPreference Bottom=\"36\" ColumnCount=\"1\" ColumnDirection=\"Horizontal\" ColumnGutter=\"12\" ColumnsPositions=\"0 426.8976377953\" Left=\"36\" Right=\"36\" Top=\"36\" />\n",
      "\t\t\t<GridDataInformation CharacterAki=\"0\" CharacterAlignment=\"AlignEmCenter\" FontStyle=\"Regular\" GridAlignment=\"AlignEmCenter\" HorizontalScale=\"100\" LineAki=\"9\" LineAlignment=\"LeftOrTopLineJustify\" PointSize=\"12\" VerticalScale=\"100\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<AppliedFont type=\"string\">Minion Pro</AppliedFont>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</GridDataInformation>\n",
      "\t\t</Page>\n",
      "\t\t<Page AppliedAlternateLayout=\"uf0\" AppliedMaster=\"uf1\" AppliedTrapPreset=\"TrapPreset/$ID/kDefaultTrapStyleName\" GeometricBounds=\"0 0 708.6614173237 498.8976377953\" GridStartingPoint=\"TopOutside\" ItemTransform=\"1 0 0 1 0 -354.33070866185\" LayoutRule=\"UseMaster\" MasterPageTransform=\"1 0 0 1 0 0\" Name=\"3\" OptionalPage=\"false\" OverrideList=\"\" Self=\"ue3\" SnapshotBlendingMode=\"IgnoreLayoutSnapshots\" TabOrder=\"\" UseMasterGrid=\"true\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<PageColor type=\"enumeration\">UseMasterColor</PageColor>\n",
      "\t\t\t\t<Descriptor type=\"list\">\n",
      "\t\t\t\t\t<ListItem type=\"string\" />\n",
      "\t\t\t\t\t<ListItem type=\"enumeration\">Arabic</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"boolean\">true</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"boolean\">false</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"long\">3</ListItem>\n",
      "\t\t\t\t\t<ListItem type=\"string\" />\n",
      "\t\t\t\t</Descriptor>\n",
      "\t\t\t</Properties>\n",
      "\t\t\t<MarginPreference Bottom=\"36\" ColumnCount=\"1\" ColumnDirection=\"Horizontal\" ColumnGutter=\"12\" ColumnsPositions=\"0 426.8976377953\" Left=\"36\" Right=\"36\" Top=\"36\" />\n",
      "\t\t\t<GridDataInformation CharacterAki=\"0\" CharacterAlignment=\"AlignEmCenter\" FontStyle=\"Regular\" GridAlignment=\"AlignEmCenter\" HorizontalScale=\"100\" LineAki=\"9\" LineAlignment=\"LeftOrTopLineJustify\" PointSize=\"12\" VerticalScale=\"100\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<AppliedFont type=\"string\">Minion Pro</AppliedFont>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</GridDataInformation>\n",
      "\t\t</Page>\n",
      "\t\t<TextFrame AppliedObjectStyle=\"ObjectStyle/$ID/[Normal Graphics Frame]\" ContentType=\"TextType\" GradientFillAngle=\"0\" GradientFillHiliteAngle=\"0\" GradientFillHiliteLength=\"0\" GradientFillLength=\"0\" GradientFillStart=\"0 0\" GradientStrokeAngle=\"0\" GradientStrokeHiliteAngle=\"0\" GradientStrokeHiliteLength=\"0\" GradientStrokeLength=\"0\" GradientStrokeStart=\"0 0\" HorizontalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" ItemLayer=\"uc5\" ItemTransform=\"1 0 0 1 -461.8976377953 -154.90551181145634\" LastUpdatedInterfaceChangeCount=\"\" LocalDisplaySetting=\"Default\" Locked=\"false\" Name=\"$ID/\" NextTextFrame=\"u30f\" OverriddenPageItemProps=\"\" ParentInterfaceChangeCount=\"\" ParentStory=\"u2ee\" PreviousTextFrame=\"u300\" Self=\"u309\" TargetInterfaceChangeCount=\"\" VerticalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" Visible=\"true\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<PathGeometry>\n",
      "\t\t\t\t\t<GeometryPathType PathOpen=\"false\">\n",
      "\t\t\t\t\t\t<PathPointArray>\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"0.38878924057183895 -163.92519685039372\" LeftDirection=\"0.38878924057183895 -163.92519685039372\" RightDirection=\"0.38878924057183895 -163.92519685039372\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"-0.5 472.7362204733064\" LeftDirection=\"-0.5 472.7362204733064\" RightDirection=\"-0.5 472.7362204733064\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"425.3976377953 472.7362204733064\" LeftDirection=\"425.3976377953 472.7362204733064\" RightDirection=\"425.3976377953 472.7362204733064\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"426.28642703587184 -163.92519685039372\" LeftDirection=\"426.28642703587184 -163.92519685039372\" RightDirection=\"426.28642703587184 -163.92519685039372\" />\n",
      "\t\t\t\t\t\t</PathPointArray>\n",
      "\t\t\t\t\t</GeometryPathType>\n",
      "\t\t\t\t</PathGeometry>\n",
      "\t\t\t</Properties>\n",
      "\t\t\t<ObjectExportOption ActualTextSourceType=\"SourceXMLStructure\" AltTextSourceType=\"SourceXMLStructure\" ApplyTagType=\"TagFromStructure\" CustomActualText=\"$ID/\" CustomAltText=\"$ID/\" CustomImageAlignment=\"false\" CustomLayout=\"false\" CustomLayoutType=\"AlignmentAndSpacing\" CustomSize=\"$ID/\" EpubType=\"$ID/\" GIFOptionsInterlaced=\"true\" GIFOptionsPalette=\"AdaptivePalette\" ImageAlignment=\"AlignLeft\" ImageConversionType=\"JPEG\" ImageExportResolution=\"Ppi300\" ImagePageBreak=\"PageBreakBefore\" ImageSpaceAfter=\"0\" ImageSpaceBefore=\"0\" JPEGOptionsFormat=\"BaselineEncoding\" JPEGOptionsQuality=\"High\" PreserveAppearanceFromLayout=\"PreserveAppearanceDefault\" SizeType=\"DefaultSize\" SpaceUnit=\"CssPixel\" UseImagePageBreak=\"false\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<AltMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
      "\t\t\t\t\t<ActualMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</ObjectExportOption>\n",
      "\t\t\t<TextFramePreference AutoSizingReferencePoint=\"CenterPoint\" AutoSizingType=\"Off\" FirstBaselineOffset=\"AscentOffset\" FootnotesEnableOverrides=\"false\" FootnotesMinimumSpacing=\"12\" FootnotesSpaceBetween=\"6\" FootnotesSpanAcrossColumns=\"false\" IgnoreWrap=\"false\" MinimumFirstBaselineOffset=\"0\" MinimumHeightForAutoSizing=\"0\" MinimumWidthForAutoSizing=\"0\" TextColumnCount=\"1\" TextColumnFixedWidth=\"425.78642703587184\" TextColumnGutter=\"12\" TextColumnMaxWidth=\"0\" UseFixedColumnWidth=\"false\" UseFlexibleColumnWidth=\"false\" UseMinimumHeightForAutoSizing=\"false\" UseMinimumWidthForAutoSizing=\"false\" UseNoLineBreaksForAutoSizing=\"false\" VerticalBalanceColumns=\"false\" VerticalJustification=\"TopAlign\" VerticalThreshold=\"0\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<InsetSpacing type=\"unit\">0</InsetSpacing>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</TextFramePreference>\n",
      "\t\t\t<BaselineFrameGridOption BaselineFrameGridIncrement=\"12\" BaselineFrameGridRelativeOption=\"TopOfInset\" StartingOffsetForBaselineFrameGrid=\"0\" UseCustomBaselineFrameGrid=\"false\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<BaselineFrameGridColor type=\"enumeration\">LightBlue</BaselineFrameGridColor>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</BaselineFrameGridOption>\n",
      "\t\t\t<TextFrameFootnoteOptionsObject EnableOverrides=\"false\" MinimumSpacingOption=\"12\" SpaceBetweenFootnotes=\"6\" SpanFootnotesAcross=\"false\" />\n",
      "\t\t\t<TextWrapPreference ApplyToMasterPageOnly=\"false\" Inverse=\"false\" TextWrapMode=\"None\" TextWrapSide=\"BothSides\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<TextWrapOffset Bottom=\"0\" Left=\"0\" Right=\"0\" Top=\"0\" />\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</TextWrapPreference>\n",
      "\t\t</TextFrame>\n",
      "\t\t<TextFrame AppliedObjectStyle=\"ObjectStyle/$ID/[Normal Graphics Frame]\" ContentType=\"TextType\" GradientFillAngle=\"0\" GradientFillHiliteAngle=\"0\" GradientFillHiliteLength=\"0\" GradientFillLength=\"0\" GradientFillStart=\"0 0\" GradientStrokeAngle=\"0\" GradientStrokeHiliteAngle=\"0\" GradientStrokeHiliteLength=\"0\" GradientStrokeLength=\"0\" GradientStrokeStart=\"0 0\" HorizontalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" ItemLayer=\"uc5\" ItemTransform=\"1 0 0 1 37 -234.27559055161385\" LastUpdatedInterfaceChangeCount=\"\" LocalDisplaySetting=\"Default\" Locked=\"false\" Name=\"$ID/\" NextTextFrame=\"u319\" OverriddenPageItemProps=\"\" ParentInterfaceChangeCount=\"\" ParentStory=\"u2ee\" PreviousTextFrame=\"u309\" Self=\"u30f\" TargetInterfaceChangeCount=\"\" VerticalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" Visible=\"true\">\n",
      "\t\t\t<Properties>\n",
      "\t\t\t\t<PathGeometry>\n",
      "\t\t\t\t\t<GeometryPathType PathOpen=\"false\">\n",
      "\t\t\t\t\t\t<PathPointArray>\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"-2.8546852336303488 -85.55511811023621\" LeftDirection=\"-2.8546852336303488 -85.55511811023621\" RightDirection=\"-2.8546852336303488 -85.55511811023621\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"-0.5 552.1062992134638\" LeftDirection=\"-0.5 552.1062992134638\" RightDirection=\"-0.5 552.1062992134638\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"425.3976377953 552.1062992134638\" LeftDirection=\"425.3976377953 552.1062992134638\" RightDirection=\"425.3976377953 552.1062992134638\" />\n",
      "\t\t\t\t\t\t\t<PathPointType Anchor=\"423.04295256166967 -85.55511811023621\" LeftDirection=\"423.04295256166967 -85.55511811023621\" RightDirection=\"423.04295256166967 -85.55511811023621\" />\n",
      "\t\t\t\t\t\t</PathPointArray>\n",
      "\t\t\t\t\t</GeometryPathType>\n",
      "\t\t\t\t</PathGeometry>\n",
      "\t\t\t</Properties>\n",
      "\t\t\t<ObjectExportOption ActualTextSourceType=\"SourceXMLStructure\" AltTextSourceType=\"SourceXMLStructure\" ApplyTagType=\"TagFromStructure\" CustomActualText=\"$ID/\" CustomAltText=\"$ID/\" CustomImageAlignment=\"false\" CustomLayout=\"false\" CustomLayoutType=\"AlignmentAndSpacing\" CustomSize=\"$ID/\" EpubType=\"$ID/\" GIFOptionsInterlaced=\"true\" GIFOptionsPalette=\"AdaptivePalette\" ImageAlignment=\"AlignLeft\" ImageConversionType=\"JPEG\" ImageExportResolution=\"Ppi300\" ImagePageBreak=\"PageBreakBefore\" ImageSpaceAfter=\"0\" ImageSpaceBefore=\"0\" JPEGOptionsFormat=\"BaselineEncoding\" JPEGOptionsQuality=\"High\" PreserveAppearanceFromLayout=\"PreserveAppearanceDefault\" SizeType=\"DefaultSize\" SpaceUnit=\"CssPixel\" UseImagePageBreak=\"false\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<AltMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
      "\t\t\t\t\t<ActualMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</ObjectExportOption>\n",
      "\t\t\t<TextFramePreference AutoSizingReferencePoint=\"CenterPoint\" AutoSizingType=\"Off\" FirstBaselineOffset=\"AscentOffset\" FootnotesEnableOverrides=\"false\" FootnotesMinimumSpacing=\"12\" FootnotesSpaceBetween=\"6\" FootnotesSpanAcrossColumns=\"false\" IgnoreWrap=\"false\" MinimumFirstBaselineOffset=\"0\" MinimumHeightForAutoSizing=\"0\" MinimumWidthForAutoSizing=\"0\" TextColumnCount=\"1\" TextColumnFixedWidth=\"427.25232302893033\" TextColumnGutter=\"12\" TextColumnMaxWidth=\"0\" UseFixedColumnWidth=\"false\" UseFlexibleColumnWidth=\"false\" UseMinimumHeightForAutoSizing=\"false\" UseMinimumWidthForAutoSizing=\"false\" UseNoLineBreaksForAutoSizing=\"false\" VerticalBalanceColumns=\"false\" VerticalJustification=\"TopAlign\" VerticalThreshold=\"0\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<InsetSpacing type=\"unit\">0</InsetSpacing>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</TextFramePreference>\n",
      "\t\t\t<BaselineFrameGridOption BaselineFrameGridIncrement=\"12\" BaselineFrameGridRelativeOption=\"TopOfInset\" StartingOffsetForBaselineFrameGrid=\"0\" UseCustomBaselineFrameGrid=\"false\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<BaselineFrameGridColor type=\"enumeration\">LightBlue</BaselineFrameGridColor>\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</BaselineFrameGridOption>\n",
      "\t\t\t<TextFrameFootnoteOptionsObject EnableOverrides=\"false\" MinimumSpacingOption=\"12\" SpaceBetweenFootnotes=\"6\" SpanFootnotesAcross=\"false\" />\n",
      "\t\t\t<TextWrapPreference ApplyToMasterPageOnly=\"false\" Inverse=\"false\" TextWrapMode=\"None\" TextWrapSide=\"BothSides\">\n",
      "\t\t\t\t<Properties>\n",
      "\t\t\t\t\t<TextWrapOffset Bottom=\"0\" Left=\"0\" Right=\"0\" Top=\"0\" />\n",
      "\t\t\t\t</Properties>\n",
      "\t\t\t</TextWrapPreference>\n",
      "\t\t</TextFrame>\n",
      "\t</Spread>\n",
      "</ns0:Spread>\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse('../idml2html/' + idml.spreads[1])\n",
    "print(ET.tostring(tree.getroot(), encoding='utf8').decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='utf8'?>\n",
      "<ns0:Story xmlns:ns0=\"http://ns.adobe.com/AdobeInDesign/idml/1.0/packaging\" DOMVersion=\"14.0\">\n",
      "\t<Story AppliedNamedGrid=\"n\" AppliedTOCStyle=\"n\" IsEndnoteStory=\"false\" Self=\"u2ee\" StoryTitle=\"$ID/\" TrackChanges=\"false\" UserText=\"true\">\n",
      "\t\t<StoryPreference FrameType=\"TextFrameType\" OpticalMarginAlignment=\"false\" OpticalMarginSize=\"12\" StoryDirection=\"LeftToRightDirection\" StoryOrientation=\"Horizontal\" />\n",
      "\t\t<InCopyExportOption IncludeAllResources=\"false\" IncludeGraphicProxies=\"true\" />\n",
      "\t\t<ParagraphStyleRange AppliedParagraphStyle=\"ParagraphStyle/$ID/NormalParagraphStyle\">\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t</ParagraphStyleRange>\n",
      "\t\t<ParagraphStyleRange AppliedParagraphStyle=\"ParagraphStyle/$ID/NormalParagraphStyle\">\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t</ParagraphStyleRange>\n",
      "\t</Story>\n",
      "</ns0:Story>\n"
     ]
    }
   ],
   "source": [
    "# for spread in idml.spreads:\n",
    "#     tree = ET.parse('../idml2html/' + spread)\n",
    "#     root = tree.getroot()\n",
    "#     for page in root.iter(\"Page\"):\n",
    "#         print(page.attrib)\n",
    "\n",
    "tree = ET.parse('../idml2html/' + idml.stories[0])\n",
    "print(ET.tostring(tree.getroot(), encoding='utf8').decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stories/Story_u2ee.xml', 'Stories/Story_u1b1.xml']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idml.stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version='1.0' encoding='utf8'?>\n",
      "<ns0:Story xmlns:ns0=\"http://ns.adobe.com/AdobeInDesign/idml/1.0/packaging\" DOMVersion=\"14.0\">\n",
      "\t<Story AppliedNamedGrid=\"n\" AppliedTOCStyle=\"n\" IsEndnoteStory=\"false\" Self=\"u2ee\" StoryTitle=\"$ID/\" TrackChanges=\"false\" UserText=\"true\">\n",
      "\t\t<StoryPreference FrameType=\"TextFrameType\" OpticalMarginAlignment=\"false\" OpticalMarginSize=\"12\" StoryDirection=\"LeftToRightDirection\" StoryOrientation=\"Horizontal\" />\n",
      "\t\t<InCopyExportOption IncludeAllResources=\"false\" IncludeGraphicProxies=\"true\" />\n",
      "\t\t<ParagraphStyleRange AppliedParagraphStyle=\"ParagraphStyle/$ID/NormalParagraphStyle\">\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t</ParagraphStyleRange>\n",
      "\t\t<ParagraphStyleRange AppliedParagraphStyle=\"ParagraphStyle/$ID/NormalParagraphStyle\">\n",
      "\t\t\t<CharacterStyleRange AppliedCharacterStyle=\"CharacterStyle/$ID/[No character style]\">\n",
      "\t\t\t\t<Content>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</Content>\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Br />\n",
      "\t\t\t\t<Content>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</Content>\n",
      "\t\t\t</CharacterStyleRange>\n",
      "\t\t</ParagraphStyleRange>\n",
      "\t</Story>\n",
      "</ns0:Story>\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse('../idml2html/' + idml.stories[0])\n",
    "print(ET.tostring(tree.getroot(), encoding='utf8').decode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Self': 'Color/Black', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 0 0 100', 'ColorOverride': 'Specialblack', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'Black', 'ColorEditable': 'false', 'ColorRemovable': 'false', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch3'}\n",
      "{'Self': 'Color/C=0 M=0 Y=100 K=0', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 0 100 0', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'C=0 M=0 Y=100 K=0', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch6'}\n",
      "{'Self': 'Color/C=0 M=100 Y=0 K=0', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 100 0 0', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'C=0 M=100 Y=0 K=0', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch5'}\n",
      "{'Self': 'Color/C=100 M=0 Y=0 K=0', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '100 0 0 0', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'C=100 M=0 Y=0 K=0', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch4'}\n",
      "{'Self': 'Color/C=100 M=90 Y=10 K=0', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '100 90 10 0', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'C=100 M=90 Y=10 K=0', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch9'}\n",
      "{'Self': 'Color/C=15 M=100 Y=100 K=0', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '15 100 100 0', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'C=15 M=100 Y=100 K=0', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch7'}\n",
      "{'Self': 'Color/C=75 M=5 Y=100 K=0', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '75 5 100 0', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'C=75 M=5 Y=100 K=0', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch8'}\n",
      "{'Self': 'Color/Cyan', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '100 0 0 0', 'ColorOverride': 'Hiddenreserved', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'Cyan', 'ColorEditable': 'false', 'ColorRemovable': 'false', 'Visible': 'false', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'n'}\n",
      "{'Self': 'Color/Magenta', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 100 0 0', 'ColorOverride': 'Hiddenreserved', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'Magenta', 'ColorEditable': 'false', 'ColorRemovable': 'false', 'Visible': 'false', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'n'}\n",
      "{'Self': 'Color/Paper', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 0 0 0', 'ColorOverride': 'Specialpaper', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'Paper', 'ColorEditable': 'true', 'ColorRemovable': 'false', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch2'}\n",
      "{'Self': 'Color/Registration', 'Model': 'Registration', 'Space': 'CMYK', 'ColorValue': '100 100 100 100', 'ColorOverride': 'Specialregistration', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'Registration', 'ColorEditable': 'false', 'ColorRemovable': 'false', 'Visible': 'true', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'u18ColorGroupSwatch1'}\n",
      "{'Self': 'Color/Yellow', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 0 100 0', 'ColorOverride': 'Hiddenreserved', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': 'Yellow', 'ColorEditable': 'false', 'ColorRemovable': 'false', 'Visible': 'false', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'n'}\n",
      "{'Self': 'Color/u8d', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 0 0 100', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': '$ID/', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'false', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'n'}\n",
      "{'Self': 'Color/u8f', 'Model': 'Process', 'Space': 'CMYK', 'ColorValue': '0 0 0 0', 'ColorOverride': 'Normal', 'AlternateSpace': 'NoAlternateColor', 'AlternateColorValue': '', 'Name': '$ID/', 'ColorEditable': 'true', 'ColorRemovable': 'true', 'Visible': 'false', 'SwatchCreatorID': '7937', 'SwatchColorGroupReference': 'n'}\n"
     ]
    }
   ],
   "source": [
    "tree = ET.parse('../idml2html/' + idml.graphic.name)\n",
    "for i in tree.getroot().iter(\"Color\"):\n",
    "    print(i.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p style='text-align: left'><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span><br /><span style='font-weight: normal;font-size: 8pt;'>Building high quality training datasets is one of the most difficult challenges of machine learning solutions in the real world. Disciplines like deep learning have helped us to build more accurate models but, to do so, they require vastly larger volumes of training data. Now, saying that effective machine learning requires a lot of training data is like saying that “you need a lot of money to be rich”. It’s true, but it doesn’t make it less painful to get there. In many of the machine learning projects we work on at Invector Labs, our customers spend significant more time collecting and labeling training dataset than building machine learning models. Last year, we came across a small project created by artificial intelligence(AI) researchers from Stanford University that provides a programming model for the creation of training datasets. Ever since, Snorkel has become a regular component of our machine learning implementations.</span><br /><br /><span style='font-weight: normal;font-size: 8pt;'>If we think about the traditional process for building a training dataset it involves three major steps: data collection, data labeling and feature engineering. From the complexity standpoint, data collection is fundamentally trivial as most organizations understand what data sources they have. Feature engineering is getting to the point that is 70%-80% automated using algorithms. The real effort is in the data labeling stage.</span></p>\n"
     ]
    }
   ],
   "source": [
    "def get_alignment(args): \n",
    "    switcher = { \n",
    "        \"CenterAlign\": \"text-align: center\", \n",
    "        \"RightAlign\": \"text-align: right\", \n",
    "        \"LeftAlign\": \"text-align: left\", \n",
    "    } \n",
    "  \n",
    "    return switcher.get(args, switcher[\"LeftAlign\"]) \n",
    "\n",
    "def get_font_weight(args):\n",
    "    switcher = { \n",
    "        \"Bold\": \"font-weight: bold\", \n",
    "        \"Italics\": \"font-weight: italics\", \n",
    "        \"Normal\": \"font-weight: normal\", \n",
    "    }\n",
    "  \n",
    "    return switcher.get(args, switcher[\"Normal\"]) \n",
    "\n",
    "def get_font_size(args):\n",
    "    return \"font-size: \" + args + \"pt\" if args else \"font-size: 8pt\"\n",
    "\n",
    "\n",
    "# Parent styles\n",
    "\n",
    "finalChild = \"\"\n",
    "\n",
    "for story in idml.stories:\n",
    "    tree = ET.parse('../idml2html/' + story)\n",
    "    root = tree.getroot()\n",
    "    strContent = ''\n",
    "    \n",
    "    paragraphStyleRanges = root.iter(\"ParagraphStyleRange\")\n",
    "    \n",
    "    for paragraphStyleRange in paragraphStyleRanges:\n",
    "        parentStyle = \"\"\n",
    "        alignment = paragraphStyleRange.attrib.get(\"Justification\")\n",
    "        alignment = get_alignment(alignment)\n",
    "        parentStyle += \"<p style='\" + alignment + \"'>\"\n",
    "        \n",
    "        # Parent styles\n",
    "        characterStyleRanges = paragraphStyleRange.iter('CharacterStyleRange')\n",
    "        childStyle = \"\"\n",
    "        for characterStyleRange in characterStyleRanges:\n",
    "            fontStyle = characterStyleRange.attrib.get(\"FontStyle\")\n",
    "            fontStyle = get_font_weight(fontStyle)\n",
    "            \n",
    "            fontSize = characterStyleRange.attrib.get(\"PointSize\")\n",
    "            fontSize = get_font_size(fontSize)\n",
    "            \n",
    "            childrens = [i for i in characterStyleRange.iter()]\n",
    "            \n",
    "            for child in childrens:\n",
    "                if child.tag == \"Content\":\n",
    "                    childStyle += \"<span style='\" + fontStyle + \";\"\n",
    "                    childStyle += fontSize + \";\" if fontSize else \"\"\n",
    "                    childStyle += \"'>\" + child.text if child.text else \"'>\" \n",
    "                    childStyle += \"</span>\"\n",
    "                \n",
    "                if child.tag == \"Br\":\n",
    "                    childStyle += \"<br />\"\n",
    "                    \n",
    "        finalChild += childStyle\n",
    "                                 \n",
    "strContent += parentStyle + finalChild + \"</p>\"\n",
    "\n",
    "print(strContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-38d1c85262c8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-38d1c85262c8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n",
    "<idPkg:MasterSpread xmlns:idPkg=\"http://ns.adobe.com/AdobeInDesign/idml/1.0/packaging\" DOMVersion=\"14.0\">\n",
    "        <MasterSpread Self=\"ub2\" Name=\"A-Master\" NamePrefix=\"A\" BaseName=\"Master\" ShowMasterItems=\"true\" PageCount=\"2\" OverriddenPageItemProps=\"\" PrimaryTextFrame=\"n\" ItemTransform=\"1 0 0 1 0 0\">\n",
    "                <Properties>\n",
    "                        <PageColor type=\"enumeration\">UseMasterColor</PageColor>\n",
    "                </Properties>\n",
    "                <Page Self=\"ub7\" TabOrder=\"\" AppliedMaster=\"n\" OverrideList=\"\" MasterPageTransform=\"1 0 0 1 0 0\" Name=\"A\" AppliedTrapPreset=\"TrapPreset/$ID/kDefaultTrapStyleName\" GeometricBounds=\"-18 -35.99999999999999 594 360\"ItemTransform=\"1 0 0 1 -360 -288\" AppliedAlternateLayout=\"n\" LayoutRule=\"Off\" SnapshotBlendingMode=\"IgnoreLayoutSnapshots\" OptionalPage=\"false\" GridStartingPoint=\"TopOutside\" UseMasterGrid=\"true\">\n",
    "                        <Properties>\n",
    "                                <PageColor type=\"enumeration\">UseMasterColor</PageColor>\n",
    "                        </Properties>\n",
    "                        <MarginPreference ColumnCount=\"1\" ColumnGutter=\"12\" Top=\"61.199999999999996\" Bottom=\"72\" Left=\"54\" Right=\"54\" ColumnDirection=\"Horizontal\" ColumnsPositions=\"0 288\" />\n",
    "                        <GridDataInformation FontStyle=\"Regular\" PointSize=\"12\" CharacterAki=\"0\" LineAki=\"9\" HorizontalScale=\"100\" VerticalScale=\"100\" LineAlignment=\"LeftOrTopLineJustify\" GridAlignment=\"AlignEmCenter\" CharacterAlignment=\"AlignEmCenter\">\n",
    "                                <Properties>\n",
    "                                        <AppliedFont type=\"string\">Minion Pro</AppliedFont>\n",
    "                                </Properties>\n",
    "                        </GridDataInformation>\n",
    "                </Page>\n",
    "                <Page Self=\"ub8\" TabOrder=\"\" AppliedMaster=\"n\" OverrideList=\"\" MasterPageTransform=\"1 0 0 1 0 0\" Name=\"A\" AppliedTrapPreset=\"TrapPreset/$ID/kDefaultTrapStyleName\" GeometricBounds=\"-18 0 594 396\" ItemTransform=\"10 0 1 0 -288\" AppliedAlternateLayout=\"n\" LayoutRule=\"Off\" SnapshotBlendingMode=\"IgnoreLayoutSnapshots\" OptionalPage=\"false\" GridStartingPoint=\"TopOutside\" UseMasterGrid=\"true\">\n",
    "                        <Properties>\n",
    "                                <PageColor type=\"enumeration\">UseMasterColor</PageColor>\n",
    "                        </Properties>\n",
    "                        <MarginPreference ColumnCount=\"1\" ColumnGutter=\"12\" Top=\"61.199999999999996\" Bottom=\"72\" Left=\"54\" Right=\"54\" ColumnDirection=\"Horizontal\" ColumnsPositions=\"0 288\" />\n",
    "                        <GridDataInformation FontStyle=\"Regular\" PointSize=\"12\" CharacterAki=\"0\" LineAki=\"9\" HorizontalScale=\"100\" VerticalScale=\"100\" LineAlignment=\"LeftOrTopLineJustify\" GridAlignment=\"AlignEmCenter\" CharacterAlignment=\"AlignEmCenter\">\n",
    "                                <Properties>\n",
    "                                        <AppliedFont type=\"string\">Minion Pro</AppliedFont>\n",
    "                                </Properties>\n",
    "                        </GridDataInformation>\n",
    "                </Page>\n",
    "                <TextFrame Self=\"u1a9e\" ParentStory=\"u1aa1\" PreviousTextFrame=\"n\" NextTextFrame=\"n\" ContentType=\"TextType\" OverriddenPageItemProps=\"\" AllowOverrides=\"true\" Visible=\"true\" Name=\"$ID/\" HorizontalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" VerticalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" GradientFillStart=\"0 0\" GradientFillLength=\"0\" GradientFillAngle=\"0\" GradientStrokeStart=\"0 0\" GradientStrokeLength=\"0\" GradientStrokeAngle=\"0\" ItemLayer=\"u110\" Locked=\"false\" LocalDisplaySetting=\"Default\" GradientFillHiliteLength=\"0\" GradientFillHiliteAngle=\"0\" GradientStrokeHiliteLength=\"0\" GradientStrokeHiliteAngle=\"0\" AppliedObjectStyle=\"ObjectStyle/$ID/[Normal Text Frame]\" ItemTransform=\"1 0 0 1 -220.66193847656245 263.5199999999984\" ParentInterfaceChangeCount=\"\" TargetInterfaceChangeCount=\"\" LastUpdatedInterfaceChangeCount=\"\">\n",
    "                        <Properties>\n",
    "                                <PathGeometry>\n",
    "                                        <GeometryPathType PathOpen=\"false\">\n",
    "                                                <PathPointArray>\n",
    "                                                        <PathPointType Anchor=\"15.183132934570267 -11.51999999999839\" LeftDirection=\"15.183132934570267 -11.51999999999839\" RightDirection=\"15.183132934570267 -11.51999999999839\" />\n",
    "                                                        <PathPointType Anchor=\"15.183132934570267 -4.518001098631203\" LeftDirection=\"15.183132934570267 -4.518001098631203\" RightDirection=\"15.183132934570267 -4.518001098631203\" />\n",
    "                                                        <PathPointType Anchor=\"30.140744018554642 -4.518001098631203\" LeftDirection=\"30.140744018554642 -4.518001098631203\" RightDirection=\"30.140744018554642 -4.518001098631203\" />\n",
    "                                                        <PathPointType Anchor=\"30.140744018554642 -11.51999999999839\" LeftDirection=\"30.140744018554642 -11.51999999999839\" RightDirection=\"30.140744018554642 -11.51999999999839\" />\n",
    "                                                </PathPointArray>\n",
    "                                        </GeometryPathType>\n",
    "                                </PathGeometry>\n",
    "                        </Properties>\n",
    "                        <ObjectExportOption AltTextSourceType=\"SourceXMLStructure\" ActualTextSourceType=\"SourceXMLStructure\" CustomAltText=\"$ID/\" CustomActualText=\"$ID/\" ApplyTagType=\"TagFromStructure\" ImageConversionType=\"JPEG\" ImageExportResolution=\"Ppi300\" GIFOptionsPalette=\"AdaptivePalette\" GIFOptionsInterlaced=\"true\" JPEGOptionsQuality=\"High\" JPEGOptionsFormat=\"BaselineEncoding\" ImageAlignment=\"AlignLeft\" ImageSpaceBefore=\"0\" ImageSpaceAfter=\"0\" UseImagePageBreak=\"false\" ImagePageBreak=\"PageBreakBefore\" CustomImageAlignment=\"false\" SpaceUnit=\"CssPixel\" CustomLayout=\"false\" CustomLayoutType=\"AlignmentAndSpacing\" EpubType=\"$ID/\" SizeType=\"DefaultSize\" CustomSize=\"$ID/\" PreserveAppearanceFromLayout=\"PreserveAppearanceDefault\">\n",
    "                                <Properties>\n",
    "                                        <AltMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
    "                                        <ActualMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
    "                                </Properties>\n",
    "                        </ObjectExportOption>\n",
    "                        <TextFramePreference FootnotesEnableOverrides=\"false\" FootnotesSpanAcrossColumns=\"false\" FootnotesMinimumSpacing=\"12\" FootnotesSpaceBetween=\"6\" TextColumnCount=\"1\" TextColumnFixedWidth=\"14.957611083984375\" VerticalJustification=\"CenterAlign\" TextColumnMaxWidth=\"0\" AutoSizingType=\"Off\" AutoSizingReferencePoint=\"CenterPoint\" UseMinimumHeightForAutoSizing=\"false\" MinimumHeightForAutoSizing=\"0\" UseMinimumWidthForAutoSizing=\"false\" MinimumWidthForAutoSizing=\"0\" UseNoLineBreaksForAutoSizing=\"false\">\n",
    "                                <Properties>\n",
    "                                        <InsetSpacing type=\"list\">\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                        </InsetSpacing>\n",
    "                                </Properties>\n",
    "                        </TextFramePreference>\n",
    "                        <TextFrameFootnoteOptionsObject EnableOverrides=\"false\" SpanFootnotesAcross=\"false\" MinimumSpacingOption=\"12\" SpaceBetweenFootnotes=\"6\" />\n",
    "                        <TextWrapPreference Inverse=\"false\" ApplyToMasterPageOnly=\"false\" TextWrapSide=\"BothSides\" TextWrapMode=\"None\">\n",
    "                                <Properties>\n",
    "                                        <TextWrapOffset Top=\"0\" Left=\"0\" Bottom=\"0\" Right=\"0\" />\n",
    "                                </Properties>\n",
    "                        </TextWrapPreference>\n",
    "                </TextFrame>\n",
    "                <TextFrame Self=\"u1ab6\" ParentStory=\"u1ab9\" PreviousTextFrame=\"n\" NextTextFrame=\"n\" ContentType=\"TextType\" OverriddenPageItemProps=\"\" AllowOverrides=\"true\" Visible=\"true\" Name=\"$ID/\" HorizontalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" VerticalLayoutConstraints=\"FlexibleDimension FixedDimension FlexibleDimension\" GradientFillStart=\"0 0\" GradientFillLength=\"0\" GradientFillAngle=\"0\" GradientStrokeStart=\"0 0\" GradientStrokeLength=\"0\" GradientStrokeAngle=\"0\" ItemLayer=\"u110\" Locked=\"false\" LocalDisplaySetting=\"Default\" GradientFillHiliteLength=\"0\" GradientFillHiliteAngle=\"0\" GradientStrokeHiliteLength=\"0\" GradientStrokeHiliteAngle=\"0\" AppliedObjectStyle=\"ObjectStyle/$ID/[Normal Text Frame]\" ItemTransform=\"1 0 0 1 196.28119445800752 263.52000000000055\" ParentInterfaceChangeCount=\"\" TargetInterfaceChangeCount=\"\" LastUpdatedInterfaceChangeCount=\"\">\n",
    "                        <Properties>\n",
    "                                <PathGeometry>\n",
    "                                        <GeometryPathType PathOpen=\"false\">\n",
    "                                                <PathPointArray>\n",
    "                                                        <PathPointType Anchor=\"-5.75999999999965 -11.52000000000055\" LeftDirection=\"-5.75999999999965 -11.52000000000055\" RightDirection=\"-5.75999999999965 -11.52000000000055\" />\n",
    "                                                        <PathPointType Anchor=\"-5.75999999999965 -4.518001098633363\" LeftDirection=\"-5.75999999999965 -4.518001098633363\" RightDirection=\"-5.75999999999965 -4.518001098633363\" />\n",
    "                                                        <PathPointType Anchor=\"9.197611083984608 -4.518001098633363\" LeftDirection=\"9.197611083984608 -4.518001098633363\" RightDirection=\"9.197611083984608 -4.518001098633363\" />\n",
    "                                                        <PathPointType Anchor=\"9.197611083984608 -11.52000000000055\" LeftDirection=\"9.197611083984608 -11.52000000000055\" RightDirection=\"9.197611083984608 -11.52000000000055\" />\n",
    "                                                </PathPointArray>\n",
    "                                        </GeometryPathType>\n",
    "                                </PathGeometry>\n",
    "                        </Properties>\n",
    "                        <ObjectExportOption AltTextSourceType=\"SourceXMLStructure\" ActualTextSourceType=\"SourceXMLStructure\" CustomAltText=\"$ID/\" CustomActualText=\"$ID/\" ApplyTagType=\"TagFromStructure\" ImageConversionType=\"JPEG\" ImageExportResolution=\"Ppi300\" GIFOptionsPalette=\"AdaptivePalette\" GIFOptionsInterlaced=\"true\" JPEGOptionsQuality=\"High\" JPEGOptionsFormat=\"BaselineEncoding\" ImageAlignment=\"AlignLeft\" ImageSpaceBefore=\"0\" ImageSpaceAfter=\"0\" UseImagePageBreak=\"false\" ImagePageBreak=\"PageBreakBefore\" CustomImageAlignment=\"false\" SpaceUnit=\"CssPixel\" CustomLayout=\"false\" CustomLayoutType=\"AlignmentAndSpacing\" EpubType=\"$ID/\" SizeType=\"DefaultSize\" CustomSize=\"$ID/\" PreserveAppearanceFromLayout=\"PreserveAppearanceDefault\">\n",
    "                                <Properties>\n",
    "                                        <AltMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
    "                                        <ActualMetadataProperty NamespacePrefix=\"$ID/\" PropertyPath=\"$ID/\" />\n",
    "                                </Properties>\n",
    "                        </ObjectExportOption>\n",
    "                        <TextFramePreference FootnotesEnableOverrides=\"false\" FootnotesSpanAcrossColumns=\"false\" FootnotesMinimumSpacing=\"12\" FootnotesSpaceBetween=\"6\" TextColumnCount=\"1\" TextColumnFixedWidth=\"14.957611083984375\" VerticalJustification=\"CenterAlign\" TextColumnMaxWidth=\"0\" AutoSizingType=\"Off\" AutoSizingReferencePoint=\"CenterPoint\" UseMinimumHeightForAutoSizing=\"false\" MinimumHeightForAutoSizing=\"0\" UseMinimumWidthForAutoSizing=\"false\" MinimumWidthForAutoSizing=\"0\" UseNoLineBreaksForAutoSizing=\"false\">\n",
    "                                <Properties>\n",
    "                                        <InsetSpacing type=\"list\">\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                                <ListItem type=\"unit\">0</ListItem>\n",
    "                                        </InsetSpacing>\n",
    "                                </Properties>\n",
    "                        </TextFramePreference>\n",
    "                        <TextFrameFootnoteOptionsObject EnableOverrides=\"false\" SpanFootnotesAcross=\"false\" MinimumSpacingOption=\"12\" SpaceBetweenFootnotes=\"6\" />\n",
    "                        <TextWrapPreference Inverse=\"false\" ApplyToMasterPageOnly=\"false\" TextWrapSide=\"BothSides\" TextWrapMode=\"None\">\n",
    "                                <Properties>\n",
    "                                        <TextWrapOffset Top=\"0\" Left=\"0\" Bottom=\"0\" Right=\"0\" />\n",
    "                                </Properties>\n",
    "                        </TextWrapPreference>\n",
    "                </TextFrame>\n",
    "        </MasterSpread>\n",
    "</idPkg:MasterSpread>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
